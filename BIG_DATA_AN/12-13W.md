# 14 통계 분석 기법을 이용한 가설 검정

## 교재 내용

### 통계분석

- 기술 통계
    
    데이터를 요약해 설명하는 통계 분석 기법
    
    ex : 사람들이 받는 월급을 집계해 전체 월급 평균을 구하는 것
    
- 추론 통계
    
    단순 숫자를 요약하는것을 넘어 어떤 값이 발생할 확률을 계산하는 통계 분석 기법
    
    ex : 데이터에서 성별에 따라 월급 차이가 있는 것으로 나타났을 때, 이런 차이가 우연히 발생할 확률 계산
    
    만약 이런 차이가 우연히 나타날 확률이 작다면 성별에 따른 월급 차이가 통계적으로 유의하다고 결론
    

### 통계적 추론 ( 추론 통계 )

모집단에 대한 어떤 미지의 양상을 알기 위해 통계학을 이용하여 추측하는 과정

통계학의 한 부분으로서 추론 통계학이라고 불림 - 기술 통계학과 다른 개념

모집단 전체를 표본으로 조사해야함, 그러나 경제성 또는 시기간 또는 양적접근의 한계 등의 이유로 불가능한 경우가 많아, 표본에서 얻은 정보를 가지고 추론

### 통계추론은 추정 & 가설검정으로 나눔

- 추정 : 표본을 통해 모집단 특성이 어떠한가에 대해 추측하는 과정
    - 표본평균 계산을 통해 모집단평균을 추측해보거나 모집단 평균에 대한 95% 신뢰구간의 계산과정을 나타냄
- 가설검정 : 모집단 실제값이 얼마나 되는가 하는 주장과 관련해서, 표본이 가지고 있는 정보를 이용해 가설이 올바른지 그렇지 않은지 판정하는 과정

## 기술통계와 추론통계

- 기술 통계: 데이터를 요약해 설명하는 통계 분석 기법
    - `직장의 월급 평균 계산`
- 추론 통계: 어떠한 것이 발생할 확률을 계산하는 통계 분석 기법
    - `성별에 따라 월급이 차이가 있는 경우, 이런 차이가 우연히 나타날 확률`을 계산
    - 만일 위 확률이 작다면
        - `성별에 따른 월급차이가 통계적으로 유의(statistically significant)하다`라고 결론
    - 반대로 위 확률이 크다면
        - `성별에 따른 월급차이가 통계적으로 유의하지 않다`라고 결론

## 통계적 가설 검정(statistical hypothesis test) 용어

- 귀무가설(null hypothesis)
    - 모집단이 어떠한 특징을 지닐 것으로 여겨지는 가설로서 일반적으로 ‘차이가 없다’, ‘같다’(=) 기호를 사용하여 나타낼 수 있는 가설로 흔히 H0로 나타낸다.
    - 귀무가설은 실험이나 연구를 통해 기각하고자 하는 가설로, H0로 표시한다. - - 대립가설과 상반되며 귀무가설의 기각을 통해 입증하고자 하는 주장을 관철할 수 있다.
- 대립가설(alternative hyphthesis)
    - 대립가설이란 귀무가설에 반대되는 가설로, 귀무가설이 틀렸다고 판단될 경우 채택되는 가설로 H1으로 나타낸다.
    - 대립가설은 실험이나 연구를 통해 증명하고자 하는 새로운 아이디어 혹은 가설에 해당한다.

### 통계적 가설 검정에서 두집단의 평균에 차이가 있는지 검정하는 t 검정(t-test)

- 유의확률(significance probability, asymptotic significance) 또는 p-value(probability value)
    - 실제로는 집단 간의 차이가 없는(귀무가설)데 우연히 차이가 있는 데이터가 추출될 확률
    - 귀무가설이 맞다고 가정할 때 얻은 결과보다 극단적인 결과가 관측될 확률
    

> p-vaule < 0.05우연히 차이가 있는 데이터가 추출될 확률이 매우 작다그러니 모집단은 차이가 있는 데이터이다.귀무가설을 기각하고 대립가설을 채택
> 

### 상관분석(correlation analysis)

- 두 연속 변수가 서로 관련이 있는지 검정하는 통계 분석 기법임.
    - 상관분석을 통해 도출한 상관계수(correlation coefficient)를 보면 두 변수가 얼마나 관련되어 있는지, 관련성의 정도를 파악할 수 있음.
    - 상관계수는 -1~1 사이의 값을 지니며 1에 가까울수록 관련성이 크다는 것을 의미함.
    - 상관계수가 양수면 정비례, 음수면 반비례 관계를 의미함.
    

### 유의확률 구하기

- `df.corr()` 이용화면 상관계수 알 수 있지만 유의확률은 알 수 X
- 유의확률은 scipy 패키지 stats.personr() 이용해 구할 수 있음
- `stats.pearsonr()` 분석할 변수 나열하면 상관계수와 유의확률을 출력

---

# 15 머신러닝을 이용한 예측 분석

## 소득 예측 모델 코딩 절차

전처리 → 모델 만들기 → 예측 및 성능평가

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/a6d56e0b-142d-4c6a-96eb-c26f6f272b44/Untitled.png)

Adult 데이터 : 미국인의 성별,인종 ,직업 ,학력 등 다양한 인적 정보를 담고 있는 인구 조사 데이터 → 데이터를 이용해 인적 정보로 소득을 에측하는 의사결정나무 모델을 생성, 예측

## 예측변수 & 타겟 변수

예측 변수 : 예측하는데 활용하는 변수 or 모델에 입력하는 값을 예측 변수라함

타겟 변수 : 예측하고자 하는 변수 or 모델이 출력하는 값을 타겟 변수라함 

## Adult 데이터셋

| 열 이름 | 설명 | 타입 | 예시 |
| --- | --- | --- | --- |
| age | 나이 | 숫자형 | 39, 50, 38 |
| workclass | 고용 형태 | 범주형 | 'Private', 'Self-emp-not-inc', 'Local-gov' |
| fnlwgt | 샘플 가중치 | 숫자형 | 77516, 83311, 215646 |
| education | 교육 수준 | 범주형 | 'Bachelors', 'HS-grad', '11th' |
| education_num | 교육 수준을 숫자로 표시 | 숫자형 | 13, 9, 7 |
| marital_status | 결혼 상태 | 범주형 | 'Married-civ-spouse', 'Divorced', 'Never-married' |
| occupation | 직업 | 범주형 | 'Tech-support', 'Craft-repair', 'Other-service' |
| relationship | 가족 관계 | 범주형 | 'Wife', 'Own-child', 'Husband' |
| race | 인종 | 범주형 | 'White', 'Black', 'Asian-Pac-Islander' |
| sex | 성별 | 범주형 | 'Male', 'Female' |
| capital_gain | 자본 이익 | 숫자형 | 2174, 0, 14084 |
| capital_loss | 자본 손실 | 숫자형 | 0, 1902, 1887 |
| hours_per_week | 주당 근로 시간 | 숫자형 | 40, 13, 60 |
| native_country | 출신 국가 | 범주형 | 'United-States', 'Cuba', 'Jamaica' |
| income | 소득 수준 (타겟 열) | 범주형 | '>50K', '<=50K' |

### ***기말시험***

```python
df = df.drop(columns = 'fnlwgt') # 샘플(인구통계가중치), 기말고사
```

### 문자 타입 변수를 숫자 타입으로 바꾸기 ( 원-핫 인코딩 )

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/76737a32-3d50-44e9-b19e-f6714df12782/Untitled.png)

***원-핫 인코딩 : 범주형 변수들을 이진수 변수로 변환***

```python
df_tmp = pd.get_dummies(df_tmp)
df_tmp.info()
```

- `df_tmp` 데이터프레임의 문자 타입 변수를 원핫 인코딩(one-hot encoding)하여 새로운 형태로 변환한 후, 데이터프레임의 정보를 출력하는 코드
- 이 과정을 통해 범주형 변수가 0과 1로 이루어진 이진 변수들로 변환
- 머신러닝 모델이 범주형 데이터를 보다 잘 처리할 수 있게 됨

## 사이킷런 ( Sckikit-learn )

- 파이썬에서 사용할 수 있는 머신러닝 라이브러리
- 간단하고 효과적인 도구 제공
- 데이터 마이닝과 데이터 분석을 위한 다양한 기능 제공 , 사용하기 쉬운 API와 많은 문서화로 머신러닝 모델을 개발하고 평가하는 것이 용이
- 오픈소스

사이킷런 주요 기능

- 다양한 알고리즘 → 분류, 회귀, 군집화, 차원 축소 등 다양한 머신러닝 알고리즘 제공
- 데이터 전처리 기능
- 모델 평가 및 선택 → 교차 검증 ,그리드 서치와 같은 기능으로 모델 평가
- 폭 넓은 지원

```python

from sklearn.model_selection import train_test_split
df_train, df_test = train_test_split(df,
                                     test_size = 0.3,          # 테스트 세트 비율
                                     stratify = df['income'],  # 타겟 변수 비율 유지
                                     random_state = 1234)      # 난수 고정
```

- **`df_train`**: 학습 세트로 사용될 데이터프레임.
- **`df_test`**: 테스트 세트로 사용될 데이터프레임.
- **`df`**: 전체 데이터프레임.
- **`test_size=0.3`**: 전체 데이터 중 테스트 세트의 비율을 설정. 여기서는 30%의 데이터를 테스트 세트로 사용하고, 나머지 70%를 학습 세트로 사용
- **`stratify=df['income']`**: 타겟 변수인 `income`을 기준으로 층화 샘플링(stratified sampling)을 수행. 이를 통해 학습 세트와 테스트 세트에서 `income` 변수의 클래스 비율이 원래 데이터프레임과 동일하게 유지되도록 함
- **`random_state=1234`**: 난수 생성기의 시드를 고정하여, 동일한 데이터를 입력받았을 때 항상 동일한 결과를 얻을 수 있도록 함. 재현성(reproducibility)을 보장

## 의사결정나무 ( Decision tree )

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/ef1ff5b9-d0f5-47d4-a4a5-b69e91da069d/Untitled.png)

의사결정나무 모델은 마치 스무고개 놀이처럼 순서대로 주어진 질문에 yes/no에 답하면 마지막 결론을 얻는 구조로 되어있음

**의사결정나무 모델 설정하기** 

```python
from sklearn import tree
# 모델 만들기
clf = tree.DecisionTreeClassifier(random_state = 1234,  # 난수 고정 # 시험문제 출제
                                  max_depth = 3)        # 나무 깊이
```

- **`clf`**: 결정 트리 분류 모델을 저장할 변수
- **`tree.DecisionTreeClassifier`**: 결정 트리 분류 모델을 생성하는 클래스
    - **`random_state=1234`**: 난수 생성 시드(seed)를 설정하여 모델의 재현성을 보장. 동일한 `random_state` 값을 사용하면 매번 동일한 결과를 얻을 수 있음
    - **`max_depth=3`**: 결정 트리의 최대 깊이를 설정. 트리의 깊이는 가지치기(pruning)와 관련이 있으며, 모델이 과적합(overfitting)되는 것을 방지하기 위해 깊이를 제한할 수 있음

## 지니 (gini) 계수

불평등의 정도를 나타내는 통계학적 지수

서로 다른 데이터가 비슷하게 있을수록 지니 지수는 높아짐

정보 이득의 최대화 → 불순도 감소 → 지니 지수 감소

## value [high, low] 비율

- low 비율이 높으므로 파란색
- 노트 표시의 첫 행은 다음 노드를 나누는 기준
- 노트 표시의 2행부터는 이 노드의 상태 정보를 표시
    - samples n% : 전체에서 차지하는 비율
    - value = [m,n] : 이 노드 전체에서 high와 low가 각각 차지하는 비율
    - class = 많은 비율
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/4fc870b1-8646-404f-9a0b-61a58e9ecb04/Untitled.png)
    
    ## 성능 평가 - confusion matrix (혼동 행렬)
    
    ```python
    from sklearn.metrics import confusion_matrix
    conf_mat = confusion_matrix(y_true = df_test['income'],  # 실제값
                                y_pred = df_test['pred'],    # 예측값
                                labels = ['high', 'low'])    # 클래스 배치 순서
    conf_mat
    
    ```
    
    - **`y_true`**
        - **역할**: 모델이 예측한 값을 비교할 실제 라벨(정답)
        - **설명**: 테스트 데이터프레임 `df_test`의 `income` 열에 있는 실제 라벨을 제공
    - **`y_pred`**
        - **역할**: 모델이 예측한 값
        - **설명**: 테스트 데이터프레임 `df_test`의 `pred` 열에 있는 예측 라벨을 제공
    - **`labels`**
        - **역할**: 혼동 행렬에 표시될 클래스의 순서를 지정
        - **설명**: 혼동 행렬의 행과 열이 어떤 순서로 배열될지 결정. 여기서는 `['high', 'low']` 순서로 지정하여 `high` 클래스가 첫 번째 행과 열에, `low` 클래스가 두 번째 행과 열에 위치하도록 함
        
    
    ### 혼동 행렬 (confusion matrix) 구조
    
    |  | 예측: high | 예측: low |
    | --- | --- | --- |
    | 실제: high | TP | FN |
    | 실제: low | FP | TN |
    - **TP (True Positive)**: 실제로 Positive인 샘플을 Positive로 올바르게 예측한 경우.
    - **FN (False Negative)**: 실제로 Positive인 샘플을 Negative로 잘못 예측한 경우.
    - **FP (False Positive)**: 실제로 Negative인 샘플을 Positive로 잘못 예측한 경우.
    - **TN (True Negative)**: 실제로 Negative인 샘플을 Negative로 올바르게 예측한 경우.
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/1ad42342-b766-4ff6-9af9-baeacc792f78/Untitled.png)
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/4de356ee-2eeb-4402-acd8-84bc307566d4/Untitled.png)
    
    ### Accuracy - 정확도
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/39cece83-3ecb-4be9-a0ec-22e8b55a7dd5/Untitled.png)
    
    $Accuracy=정확하게 예측한 샘플 수/전체 샘플 수$
    
    - Accuracy 값이 높을수록 예측 정확도가 높음
    - $( 1 - 잘 예측한 것 )$ $= 잘못 예측한 것$ (Error Rate)
        
        Error Rate = 1 - Accuracy
        
    - 편향의 위험 존재 → 데이터의 불균형의 원인
        - 데이터의 불균형 원인은 F1 Score로 측정
    
    ```python
    
    import sklearn.metrics as metrics
    metrics.accuracy_score(y_true = df_test['income'],  # 실제값
                           y_pred = df_test['pred'])    # 예측값
    ```
    

### precision 정밀도

모델이 긍정으로 예측한 샘플 중 실제로 긍정인 샘플의 비율을 나타냠

```python
metrics.precision_score(y_true = df_test['income'],  # 실제값
                        y_pred = df_test['pred'],    # 예측값
                        pos_label = 'high')          # 관심 클래스
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/55723a18-7f93-4427-ab78-0fbadc23f795/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/c94df2b2-2ca0-4377-b266-659bca734ba7/Untitled.png)

### 재현율 (racall) = 민감도 (sensitivity)

positive class 모델 평가할 때 사용 

- **정의**: 재현율은 실제로 긍정 클래스인 샘플 중에서 모델이 올바르게 긍정 클래스로 예측한 샘플의 비율

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/1fc43324-91c1-44de-9366-64666dec4a28/Untitled.png)

```python
metrics.recall_score(y_true = df_test['income'],  # 실제값
                     y_pred = df_test['pred'],    # 예측값
                     pos_label = 'high')          # 관심 클래스
```

**`metrics.recall_score` 함수**: 실제값과 예측값을 기반으로 특정 클래스에 대한 재현율을 계산

### F1 Score

정밀도와 재현율의 조화 평균 → 클래스가 불균형이 있는 데이터셋에서 유용

(https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/03c1b257-0c58-4bb5-8757-0902e0f428ea/Untitled.png)

```python

metrics.f1_score(y_true = df_test['income'],  # 실제값
                 y_pred = df_test['pred'],    # 예측값
                 pos_label = 'high')          # 관심 클래스
```

***산술평균과 조화평균***

- **산술평균**은 값들을 단순히 더해서 나누는 방식으로, 값들 중 하나가 낮더라도 다른 값이 높으면 평균이 크게 나올 수 있음
- **조화평균**은 값들 중 하나라도 매우 낮으면 전체 평균도 낮아지도록 계산

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/5e965540-9386-4b1a-bbf8-978857aa19b4/22b23712-33cc-4ea8-bc27-5d4ec7b9f3b6/Untitled.png)

```python
a, b = 30, 60
print(f'산술평균 = {(a + b)/ 2}, 조화평균 = {2 / (1/a + 1/b)}')
```

→ 이를 사용하는 이유는 정밀도와 재현율 둘중에 하나라도 매우 낮으면 F1 점수도 낮아지게 하기 위해서이다
